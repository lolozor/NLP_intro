{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V8FsvOED8UlF"
   },
   "source": [
    "Задание<br>\n",
    "Берем отызывы за лето (из архива с материалами или предыдущего занятия)\n",
    "1. Учим conv сеть для классификации\n",
    "2. Рассмотреть 2-а варианта сеточек\n",
    "2.1 Инициализировать tf.keras.layers.Embedding предобученными векторами взять к примеру с https://rusvectores.org/ru/\n",
    "2.2 Инициализировать слой tf.keras.layers.Embedding по умолчанию (ну то есть вам ничего не делать с весами)\n",
    "\n",
    "Сравнить две архитектуры с предобученными весами и когда tf.keras.layers.Embedding обучается сразу со всей сеточкой, что получилось лучше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2H5tFUEMCE7d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LUCk-5M2yg3S"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Content</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>It just works!</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>В целом удобноное приложение...из минусов хотя...</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Отлично все</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Стал зависать на 1% работы антивируса. Дальше ...</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Очень удобно, работает быстро.</td>\n",
       "      <td>2017-08-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating                                            Content        Date\n",
       "0       5                                     It just works!  2017-08-14\n",
       "1       4  В целом удобноное приложение...из минусов хотя...  2017-08-14\n",
       "2       5                                        Отлично все  2017-08-14\n",
       "3       5  Стал зависать на 1% работы антивируса. Дальше ...  2017-08-14\n",
       "4       5                     Очень удобно, работает быстро.  2017-08-14"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel('отзывы за лето.xls')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 566,
     "status": "ok",
     "timestamp": 1590650140159,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -240
    },
    "id": "KBSf-OfDzWOI",
    "outputId": "8b28d120-8490-44b3-cb86-6a1267ef1ad1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qEyvOxoOJDTP"
   },
   "source": [
    "### Предобработка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "from stop_words import get_stop_words\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Content</th>\n",
       "      <th>Date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>It just works!</td>\n",
       "      <td>2017-08-14</td>\n",
       "      <td>it just works</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>В целом удобноное приложение...из минусов хотя...</td>\n",
       "      <td>2017-08-14</td>\n",
       "      <td>целое удобноной приложениеиз минус хотеть боль...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Отлично все</td>\n",
       "      <td>2017-08-14</td>\n",
       "      <td>отлично</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Стал зависать на 1% работы антивируса. Дальше ...</td>\n",
       "      <td>2017-08-14</td>\n",
       "      <td>зависать 1 работа антивирус ранее пользоваться...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Очень удобно, работает быстро.</td>\n",
       "      <td>2017-08-14</td>\n",
       "      <td>удобно работать быстро</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating                                            Content        Date  \\\n",
       "0       5                                     It just works!  2017-08-14   \n",
       "1       4  В целом удобноное приложение...из минусов хотя...  2017-08-14   \n",
       "2       5                                        Отлично все  2017-08-14   \n",
       "3       5  Стал зависать на 1% работы антивируса. Дальше ...  2017-08-14   \n",
       "4       5                     Очень удобно, работает быстро.  2017-08-14   \n",
       "\n",
       "                                                text  \n",
       "0                                      it just works  \n",
       "1  целое удобноной приложениеиз минус хотеть боль...  \n",
       "2                                            отлично  \n",
       "3  зависать 1 работа антивирус ранее пользоваться...  \n",
       "4                             удобно работать быстро  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sw = set(get_stop_words(\"ru\"))\n",
    "exclude = set(punctuation)\n",
    "morpher = MorphAnalyzer()\n",
    "\n",
    "def preprocess_text(txt):\n",
    "    txt = str(txt)\n",
    "    txt = \"\".join(c for c in txt if c not in exclude)\n",
    "    txt = txt.lower()\n",
    "    txt = re.sub(\"\\sне\", \"не\", txt)\n",
    "    txt = [morpher.parse(word)[0].normal_form for word in txt.split() if word not in sw]\n",
    "    return \" \".join(txt)\n",
    "\n",
    "df['text'] = df['Content'].apply(preprocess_text)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C4o9QgmWI3Pw"
   },
   "outputs": [],
   "source": [
    "train_corpus = \" \".join(df[\"text\"])\n",
    "train_corpus = train_corpus.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10183,
     "status": "ok",
     "timestamp": 1590650264825,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -240
    },
    "id": "Hed2ySbwJH6B",
    "outputId": "66a75988-b4e3-45aa-a483-adbdc766db03"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "# nltk.download(\"punkt\")\n",
    "\n",
    "tokens = word_tokenize(train_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yJ8T0fwYJYJX"
   },
   "source": [
    "Отфильтруем данные\n",
    "\n",
    "и соберём в корпус N наиболее частых токенов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EXOLVK1tJLT8"
   },
   "outputs": [],
   "source": [
    "tokens_filtered = [word for word in tokens if word.isalnum()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8qCQH5nIJoiB"
   },
   "outputs": [],
   "source": [
    "max_words = 200\n",
    "\n",
    "from nltk.probability import FreqDist\n",
    "dist = FreqDist(tokens_filtered)\n",
    "tokens_filtered_top = [pair[0] for pair in dist.most_common(max_words-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 576,
     "status": "ok",
     "timestamp": 1590650396521,
     "user": {
      "displayName": "Roman Zakharov",
      "photoUrl": "",
      "userId": "18255168926005506833"
     },
     "user_tz": -240
    },
    "id": "bRQ-6wwjJrGo",
    "outputId": "ba8ebf9e-c6aa-4703-b54f-39b561e33493"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['приложение',\n",
       " 'удобно',\n",
       " 'работать',\n",
       " 'удобный',\n",
       " 'отлично',\n",
       " 'нравиться',\n",
       " 'хороший',\n",
       " 'отличный',\n",
       " 'телефон',\n",
       " 'супер']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_filtered_top[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# df_train, df_test = train_test_split(df, test_size=0.2,  random_state=42)\n",
    "# df_train, df_val  = train_test_split(df_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tdk777qGJtz4"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "max_len = 40\n",
    "\n",
    "vocabulary = {v: k for k, v in dict(enumerate(tokens_filtered_top, 1)).items()}\n",
    "\n",
    "def text_to_sequence(text, maxlen):\n",
    "    result = []\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens_filtered = [word for word in tokens if word.isalnum()]\n",
    "    for word in tokens_filtered:\n",
    "        if word in vocabulary:\n",
    "            result.append(vocabulary[word])\n",
    "    padding = [0]*(maxlen-len(result))\n",
    "    return padding + result[-maxlen:]\n",
    "\n",
    "x_train = np.asarray([text_to_sequence(text, max_len) for text in df[\"text\"]], dtype=np.int32)\n",
    "\n",
    "# x_train = np.asarray([text_to_sequence(text, max_len) for text in df_train[\"text\"]], dtype=np.int32)\n",
    "# x_test  = np.asarray([text_to_sequence(text, max_len) for text in df_test[\"text\"]], dtype=np.int32)\n",
    "# x_val   = np.asarray([text_to_sequence(text, max_len) for text in df_val[\"text\"]], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5OULZgvkJzpj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20659, 40)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "# print(x_test.shape)\n",
    "# print(x_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pqHlf5nNJ2hl"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Input, Embedding, Conv1D, GlobalMaxPool1D \n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import TensorBoard \n",
    "from keras.objectives import categorical_crossentropy\n",
    "from keras.callbacks import EarlyStopping  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 6\n",
    "\n",
    "y_train = keras.utils.to_categorical(df[\"Rating\"], num_classes)\n",
    "# y_test  = keras.utils.to_categorical(df_test[\"Rating\"], num_classes)\n",
    "# y_val   = keras.utils.to_categorical(df_val[\"Rating\"], num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_words = 1000\n",
    "# max_len = 40\n",
    "\n",
    "# print_batch_n = 100 \n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(input_dim=max_words, \n",
    "                    output_dim=200, \n",
    "                    input_length=max_len,\n",
    "#                     weights=[model_w2v.trainables.syn1neg[:max_words]]\n",
    "         ))\n",
    "          \n",
    "model.add(Conv1D(128, 3, activation='relu'))\n",
    "model.add(Conv1D(256, 3, activation='relu'))\n",
    "model.add(Conv1D(200, 3, activation='relu'))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy']\n",
    "#               metrics=['AUC']\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20659, 40)\n",
      "(20659, 6)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "# print(x_val.shape)\n",
    "# print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "29/29 [==============================] - 10s 310ms/step - loss: 1.3410 - accuracy: 0.7289 - val_loss: 1.0193 - val_accuracy: 0.6526\n",
      "Epoch 2/15\n",
      "29/29 [==============================] - 6s 213ms/step - loss: 0.8038 - accuracy: 0.7444 - val_loss: 0.7799 - val_accuracy: 0.7430\n",
      "Epoch 3/15\n",
      "29/29 [==============================] - 6s 212ms/step - loss: 0.6593 - accuracy: 0.7676 - val_loss: 0.7583 - val_accuracy: 0.7462\n",
      "Epoch 4/15\n",
      "29/29 [==============================] - 6s 212ms/step - loss: 0.6561 - accuracy: 0.7696 - val_loss: 0.7549 - val_accuracy: 0.7425\n",
      "Epoch 5/15\n",
      "29/29 [==============================] - 6s 211ms/step - loss: 0.6326 - accuracy: 0.7805 - val_loss: 0.7557 - val_accuracy: 0.7456\n"
     ]
    }
   ],
   "source": [
    "tensorboard=TensorBoard(log_dir='./logs', write_graph=True, write_images=True)\n",
    "early_stopping=EarlyStopping(monitor='val_loss')  \n",
    "\n",
    "epochs = 15\n",
    "batch_size = 512\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.3,\n",
    "                    callbacks=[tensorboard, early_stopping]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import accuracy_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(ngram_range=(1, 2), analyzer='word', lowercase=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ft = vect.fit_transform(df['text'])\n",
    "# valid_ft = vect.transform(df_val['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "                    train_ft, \n",
    "                    df['Rating'].to_numpy(), \n",
    "                    test_size=0.33, \n",
    "                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lgr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7606336168964506"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelW2V = Word2Vec(sentences=df['text'].apply(str.split), \n",
    "                    size=100, \n",
    "                    window=5, \n",
    "                    min_count=5, \n",
    "                    workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelW2V.wv.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [[i for i in document.split()] for document in df['text'].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1314772, 2062320)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_w2v = Word2Vec(sentences=sentences, \n",
    "                     size=200, \n",
    "                     window=5,\n",
    "                     min_count=6, \n",
    "                     sg=1, \n",
    "                     hs=0, \n",
    "                     negative=10, \n",
    "                     workers=32, \n",
    "                     seed=34)\n",
    "\n",
    "model_w2v.train(sentences, total_examples=len(sentences), epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_w2v.most_similar(positive=['минус'])\n",
    "# aaa = [model_w2v.trainables.syn1neg[:max_words]]\n",
    "# print(aaa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_words = 1000\n",
    "# max_len = 40\n",
    "\n",
    "# print_batch_n = 100 \n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(input_dim=max_words, \n",
    "                    output_dim=200, \n",
    "                    input_length=max_len,\n",
    "                    weights=[model_w2v.trainables.syn1neg[:max_words]]\n",
    "         ))\n",
    "          \n",
    "model.add(Conv1D(128, 3, activation='relu'))\n",
    "model.add(Conv1D(256, 3, activation='relu'))\n",
    "model.add(Conv1D(200, 3, activation='relu'))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy']\n",
    "#               metrics=['AUC']\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "29/29 [==============================] - 8s 260ms/step - loss: 1.1202 - accuracy: 0.6584 - val_loss: 0.9389 - val_accuracy: 0.6615\n",
      "Epoch 2/15\n",
      "29/29 [==============================] - 6s 214ms/step - loss: 0.7627 - accuracy: 0.7490 - val_loss: 0.7887 - val_accuracy: 0.7349\n",
      "Epoch 3/15\n",
      "29/29 [==============================] - 6s 214ms/step - loss: 0.6777 - accuracy: 0.7655 - val_loss: 0.7660 - val_accuracy: 0.7439\n",
      "Epoch 4/15\n",
      "29/29 [==============================] - 6s 223ms/step - loss: 0.6677 - accuracy: 0.7695 - val_loss: 0.7587 - val_accuracy: 0.7462\n",
      "Epoch 5/15\n",
      "29/29 [==============================] - 6s 220ms/step - loss: 0.6511 - accuracy: 0.7732 - val_loss: 0.7663 - val_accuracy: 0.7460\n"
     ]
    }
   ],
   "source": [
    "tensorboard=TensorBoard(log_dir='./logs', write_graph=True, write_images=True)\n",
    "early_stopping=EarlyStopping(monitor='val_loss')  \n",
    "\n",
    "# epochs = 15\n",
    "# batch_size = 512\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.3,\n",
    "                    callbacks=[tensorboard, early_stopping]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "dl-nlp-cnn1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
